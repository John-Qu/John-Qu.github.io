---
layout: post
title:  "Notes for C1 GETTING STARTED"
date: 2017-09-13 11:09:04 +0800
categories: notes
---

Here is my reading notes for Chapter 1 GETTING STARTED in Prof. Guttag's book *Introduction to compuation and programming using Python*.

## What is the limitations of computaion in human history? And to what extend modern computers do?

> For most of human history, computation was limited by the speed of calculation of the human brain and the ability to record computational results with the human hand. This meant that only the smallest problems could be attacked computationally. 
>
> Even with the speed of modern computers, there are still problems that are beyond modern computational models (e.g., understanding climate change), but more and more problems are proving amenable to computational solution.

That means we can solve problems computationally, which cannot be imagined to be solved this way. That's amazing, a lot of new chance, e.g., natural languages.

> A computer does two things, and two things only: it performs calculations and it remembers the results of those calculations. But it does those two things extremely well.

Prof. Guttag arise two examples to illustrate the speed and storage abilities. But his example is not as imaginable as Prof. Grimson's. Let's take a look.

|               | Calculation Speed                        | Remember Results    |
| ------------- | ---------------------------------------- | ------------------- |
| Prof. Guttag  | Ball fell half meter, a billon instructions | One byte, one ounce |
| Prof. Grimson | Table light came, two instructions       | All of human books  |

We have sence with how fast light run, all the books' many, but no vivid sence with billon and 100GB-3,000,000 tons.

## Why does only the smallest problems could be attacked computationally in history?

> For most of human history, computation was limited by the speed of calculation of the human brain and the ability to record computational results with the human hand.

## What is computational thinking?

imperative knowledge vs declarative knowledge

> **Declarative knowledge** is composed of statements of fact. For example, “the square root of x is a number y such that y*y = x.” This is a statement of fact. Unfortunately it doesn’t tell us how to find a square root.

> **Imperative knowledge** is “how to” knowledge, or recipes for deducing information.

> A bit more formally, an **algorithm** is a finite list of instructions that describe a computation that when executed on a provided set of inputs will proceed through a set of well-defined states and eventually produce an output.

